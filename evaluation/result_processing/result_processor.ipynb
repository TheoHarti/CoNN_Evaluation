{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfLT6Y_kYOhq"
      },
      "source": [
        "# **CoNN EVALUATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Zqr_3_YJYf"
      },
      "source": [
        "## SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Jcd-V7p7G8F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import statistics\n",
        "sns.set(style=\"ticks\")\n",
        "sns.set_palette(\"colorblind\")\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVAOqBHSbQW5"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from itertools import zip_longest\n",
        "except ImportError:\n",
        "    from itertools import izip_longest as zip_longest\n",
        "\n",
        "def get_length_of_longest_list(lists):\n",
        "  longest_list_size = 0\n",
        "  for list in lists:\n",
        "    if len(list) > longest_list_size:\n",
        "      longest_list_size = len(list)\n",
        "  return longest_list_size\n",
        " # return len(max(lists, key=len))\n",
        "\n",
        "def column_wise_mean(lists):\n",
        "  longest_list_length = get_length_of_longest_list(lists)\n",
        "  mean_list = []\n",
        "  for column_index in range(0, longest_list_length):\n",
        "    sum = 0.0\n",
        "    mean_counter = 0\n",
        "    for list in lists:\n",
        "      if len(list) >= column_index + 1:\n",
        "        sum += list[column_index]\n",
        "        mean_counter += 1\n",
        "    mean_list.append(sum/mean_counter)\n",
        "  return mean_list\n",
        "\n",
        "def column_wise_mean_with_zero_fill(lists):\n",
        "  columns = zip_longest(*lists, fillvalue=0)\n",
        "  return [sum(col)/len(lists) for col in columns]\n",
        "\n",
        "def get_mean_list(df_column):\n",
        "  lists = []\n",
        "  for row_index in range(len(df_column.index)):\n",
        "    lists.append([float(x) for x in str(df_column.iloc[row_index]).split(',')])\n",
        "  return column_wise_mean(lists)\n",
        "\n",
        "def get_mean_list_with_zero_fill(df_column):\n",
        "  lists = []\n",
        "  for row_index in range(len(df_column.index)):\n",
        "    lists.append([float(x) for x in str(df_column.iloc[row_index]).split(',')])\n",
        "  return column_wise_mean_with_zero_fill(lists)\n",
        "\n",
        "def get_last_item_mean(df_column):\n",
        "  lists = []\n",
        "  for row_index in range(len(df_column.index)):\n",
        "    lists.append([float(x) for x in str(df_column.iloc[row_index]).split(',')])\n",
        "\n",
        "  sum = 0\n",
        "  for list in lists:\n",
        "    sum += list[-1]\n",
        "\n",
        "  return sum/len(lists)\n",
        "\n",
        "def get_last_item_median(df_column):\n",
        "  lists = []\n",
        "  for row_index in range(len(df_column.index)):\n",
        "    lists.append([float(x) for x in str(df_column.iloc[row_index]).split(',')])\n",
        "\n",
        "  last_item_list = []\n",
        "  for list in lists:\n",
        "    last_item_list.append(list[-1])\n",
        "\n",
        "  return statistics.median(last_item_list)\n",
        "\n",
        "def get_median_of_row_sums(df_column):\n",
        "  row_sums = []\n",
        "  for row_index in range(len(df_column.index)):\n",
        "    row_sums.append(sum([float(x) for x in str(df_column.iloc[row_index]).split(',')]))\n",
        "  return statistics.median(row_sums)\n",
        "\n",
        "def get_length_of_longest_list2(lists):\n",
        "    list_sizes = sorted([len(list) for list in lists])\n",
        "    half_length = len(list_sizes) // 2\n",
        "    return list_sizes[half_length]\n",
        "\n",
        "def column_wise_mean2(lists):\n",
        "    longest_list_length = get_length_of_longest_list2(lists)\n",
        "    mean_list = []\n",
        "    for column_index in range(0, longest_list_length):\n",
        "        sum = 0.0\n",
        "        mean_counter = 0\n",
        "        for list in lists:\n",
        "            if len(list) >= column_index + 1:\n",
        "                sum += list[column_index]\n",
        "                mean_counter += 1\n",
        "        if mean_counter > len(lists) / 2:\n",
        "            mean_list.append(sum/mean_counter)\n",
        "    return mean_list\n",
        "\n",
        "def get_mean_list2(df_column):\n",
        "    lists = []\n",
        "    for row_index in range(len(df_column.index)):\n",
        "        lists.append([float(x) for x in str(df_column.iloc[row_index]).split(',')])\n",
        "    return column_wise_mean2(lists)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wJOnYxBk2vD"
      },
      "outputs": [],
      "source": [
        "def printResults(df):\n",
        "  construction_accuracy_median = get_last_item_median(df[\"ConstructionAccuracy\"])\n",
        "  total_params_median = get_last_item_median(df[\"ConstructionTotalParameters\"])\n",
        "  pruned_params_median = get_last_item_median(df[\"ConstructionPrunedParameters\"])\n",
        "  total_params_median -= pruned_params_median\n",
        "\n",
        "  trainable_params_median = get_mean_list_with_zero_fill(df[\"ConstructionTrainableParameters\"])\n",
        "  pruned_params_median = get_mean_list_with_zero_fill(df[\"ConstructionPrunedParameters\"])\n",
        "  construction_epochs_median = get_mean_list_with_zero_fill(df[\"ConstructionStepEpochs\"])\n",
        "  construction_effort = np.sum(np.array(trainable_params_median) * np.array(construction_epochs_median))\n",
        "\n",
        "  printmd(\"Construction Accuracy: \" + str(construction_accuracy_median))\n",
        "  if construction_effort > 0:\n",
        "    printmd(\"Construction Effort: \" + str(math.log(construction_effort)))\n",
        "  else:\n",
        "    printmd(\"Construction Effort: N/A (Invalid value)\")\n",
        "  printmd(\"Total Parameters Median: \" + str(total_params_median))\n",
        "  printmd(\"Test Accuracy Median: \" + str(df[\"TestAccuracy\"].median()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7E3BvziVeOM"
      },
      "outputs": [],
      "source": [
        "def printComparisons(df_prune_false, df_prune_true):\n",
        "  # NORMAL\n",
        "  construction_accuracy_median = get_last_item_median(df_prune_false[\"ConstructionAccuracy\"])\n",
        "  total_params_median = get_last_item_median(df_prune_false[\"ConstructionTotalParameters\"])\n",
        "  pruned_params_median = get_last_item_median(df_prune_false[\"ConstructionPrunedParameters\"])\n",
        "  total_params_median -= pruned_params_median\n",
        "\n",
        "  trainable_params_median = get_mean_list_with_zero_fill(df_prune_false[\"ConstructionTrainableParameters\"])\n",
        "  pruned_params_median = get_mean_list_with_zero_fill(df_prune_false[\"ConstructionPrunedParameters\"])\n",
        "  construction_epochs_median = get_mean_list_with_zero_fill(df_prune_false[\"ConstructionStepEpochs\"])\n",
        "  construction_effort = np.sum(np.array(trainable_params_median) * np.array(construction_epochs_median))\n",
        "\n",
        "  # PRUNE\n",
        "  construction_accuracy_prune_median = get_last_item_median(df_prune_true[\"ConstructionAccuracy\"])\n",
        "  total_params_prune_median = get_last_item_median(df_prune_true[\"ConstructionTotalParameters\"])\n",
        "  pruned_params_prune_median = get_last_item_median(df_prune_true[\"ConstructionPrunedParameters\"])\n",
        "  total_params_prune_median -= pruned_params_prune_median\n",
        "\n",
        "  prune_trainable_params_median = get_mean_list_with_zero_fill(df_prune_true[\"ConstructionTrainableParameters\"])\n",
        "  pruned_params_prune_median = get_mean_list_with_zero_fill(df_prune_true[\"ConstructionPrunedParameters\"])\n",
        "  prune_construction_epochs_median = get_mean_list_with_zero_fill(df_prune_true[\"ConstructionStepEpochs\"])\n",
        "  prune_construction_effort = np.sum(np.array(prune_trainable_params_median) * np.array(prune_construction_epochs_median))\n",
        "\n",
        "  # DIFF\n",
        "  test_acc_diff = 100 * (df_prune_true[\"TestAccuracy\"].median() - df_prune_false[\"TestAccuracy\"].median()) / abs(df_prune_false[\"TestAccuracy\"].median())\n",
        "  total_params_diff = 100 * (total_params_prune_median - total_params_median) / abs(total_params_median)\n",
        "  construction_effort_diff = 100 * (prune_construction_effort - construction_effort) / abs(construction_effort)\n",
        "\n",
        "  # PRINT\n",
        "  printmd(\"Test Accuracy Change: \" + str(test_acc_diff) + \"%\")\n",
        "  printmd(\"Total Parameters Change: \" + str(total_params_diff) + \"%\")\n",
        "  if construction_effort is not None:\n",
        "    printmd(\"Construction Effort Change: \" + str(construction_effort_diff) + \"%\")\n",
        "  else:\n",
        "    printmd(\"Construction Effort: N/A (Invalid value)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_qcHyJn7w90"
      },
      "source": [
        "## READ DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIJaStCt7U7_"
      },
      "outputs": [],
      "source": [
        "df_results = pd.read_csv('Logs.csv', sep=';')\n",
        "\n",
        "algorithm_names = df_results['AlgorithmType'].unique().tolist()\n",
        "for algorithm_name in algorithm_names:\n",
        "    print(algorithm_names)\n",
        "    df_algo = df_results.loc[df_results['AlgorithmType'] == algorithm_name]\n",
        "    print(df_algo['Hyperparameters'].unique().tolist())\n",
        "\n",
        "dataset_names = df_results['DatasetType'].unique().tolist()\n",
        "print(dataset_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_comparisons = pd.read_csv('Comparisons.csv', sep=';')"
      ],
      "metadata": {
        "id": "QXP__qBoXxCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRcuV9CEYegh"
      },
      "source": [
        "## RESULT METRICS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o0EcTI-mPNz"
      },
      "outputs": [],
      "source": [
        "for algorithm_name in algorithm_names:\n",
        "  printmd(\"# **\" + algorithm_name + \"**\")\n",
        "  df_algorithm = df_results.loc[df_results['AlgorithmType'] == algorithm_name]\n",
        "  hyperparam_sets = df_algorithm['Hyperparameters'].unique().tolist()\n",
        "\n",
        "  for dataset_name in dataset_names:\n",
        "    printmd(\"## **\" + dataset_name + \"**\")\n",
        "    df_dataset = df_algorithm.loc[df_algorithm['DatasetType'] == dataset_name]\n",
        "\n",
        "    for hyperparam_set in hyperparam_sets:\n",
        "      df = df_dataset.loc[df_dataset['Hyperparameters'] == hyperparam_set]\n",
        "\n",
        "      if df.empty:\n",
        "        continue\n",
        "\n",
        "      printmd(\"### \" + hyperparam_set)\n",
        "\n",
        "      df_prune_false = df.loc[df['PruningActive'] == False]\n",
        "      if not df_prune_false.empty:\n",
        "        printmd(\"**Without Pruning:**\")\n",
        "        printResults(df_prune_false)\n",
        "\n",
        "      df_prune_true = df.loc[df['PruningActive'] == True]\n",
        "      if not df_prune_true.empty:\n",
        "        printmd(\"**With Pruning:**\")\n",
        "        printResults(df_prune_true)\n",
        "\n",
        "      if not df_prune_false.empty and not df_prune_true.empty:\n",
        "        printmd(\"**Pruning Comparisons:**\")\n",
        "        printComparisons(df_prune_false, df_prune_true)\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzWSwZBHmpvK"
      },
      "source": [
        "## RESULT DIAGRAMS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggr_qU-raFrS"
      },
      "source": [
        "### PERFORMANCE OVER CONSTRUCTION STEPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmW1bB3M2HNF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "for algorithm_name in algorithm_names:\n",
        "  printmd(\"# **\" + algorithm_name + \"**\")\n",
        "  df_algorithm = df_results.loc[df_results['AlgorithmType'] == algorithm_name]\n",
        "  hyperparam_sets = df_algorithm['Hyperparameters'].unique().tolist()\n",
        "\n",
        "  for dataset_name in dataset_names:\n",
        "    printmd(\"## **\" + dataset_name + \"**\")\n",
        "    df_dataset = df_algorithm.loc[df_algorithm['DatasetType'] == dataset_name]\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 5))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "    for hyperparam_set in hyperparam_sets:\n",
        "      df = df_dataset.loc[df_dataset['Hyperparameters'] == hyperparam_set]\n",
        "\n",
        "      if df.empty:\n",
        "        continue\n",
        "\n",
        "      dataset_name_actual = dataset_name\n",
        "      if dataset_name == \"Curves\":\n",
        "        dataset_name_actual = \"Moons\"\n",
        "      if dataset_name == \"Compound\":\n",
        "        dataset_name_actual = \"Classification\"\n",
        "\n",
        "      df_prune = df.loc[df['PruningActive'] == False]\n",
        "      if not df_prune.empty:\n",
        "        x = [0] + get_mean_list(df_prune[\"ConstructionStep\"])\n",
        "        y = [0.0] + get_mean_list(df_prune[\"ConstructionAccuracy\"])\n",
        "        #ax.plot(x, y, label=re.sub('[^0-9,]', '', hyperparam_set))\n",
        "        ax.plot(x, y, label=hyperparam_set)\n",
        "        #ax.set_xscale('log')\n",
        "        ax.set_title(dataset_name_actual + \" - Network Construction\", fontsize = 18)\n",
        "        #ax.set_xlim([0, len(y)])\n",
        "        ax.set_xlabel(\"Construction Step\")\n",
        "        ax.set_ylim([0, 1])\n",
        "        ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "    plt.legend(loc='lower right')\n",
        "    #plt.show()\n",
        "    plt.savefig(\"Step_\" + dataset_name_actual + \"_NoPrune\" + '.pdf')\n",
        "\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 5))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "    for hyperparam_set in hyperparam_sets:\n",
        "      df = df_dataset.loc[df_dataset['Hyperparameters'] == hyperparam_set]\n",
        "\n",
        "      if df.empty:\n",
        "        continue\n",
        "\n",
        "      dataset_name_actual = dataset_name\n",
        "      if dataset_name == \"Curves\":\n",
        "        dataset_name_actual = \"Moons\"\n",
        "      if dataset_name == \"Compound\":\n",
        "        dataset_name_actual = \"Classification\"\n",
        "\n",
        "      df_prune = df.loc[df['PruningActive'] == True]\n",
        "      if not df_prune.empty:\n",
        "        x = [0] + get_mean_list(df_prune[\"ConstructionStep\"])\n",
        "        y = [0.0] + get_mean_list(df_prune[\"ConstructionAccuracy\"])\n",
        "        #ax.plot(x, y, label=re.sub('[^0-9,]', '', hyperparam_set))\n",
        "        ax.plot(x, y, label=hyperparam_set)\n",
        "        #ax.set_xscale('log')\n",
        "        ax.set_title(dataset_name_actual + \" - Network Construction (Pruning)\", fontsize = 18)\n",
        "        #ax.set_xlim([0, len(y)])\n",
        "        ax.set_xlabel(\"Construction Step\")\n",
        "        ax.set_ylim([0, 1])\n",
        "        ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "    plt.legend(loc='lower right')\n",
        "    #plt.show()\n",
        "    plt.savefig(\"Step_\" + dataset_name_actual + \"_Prune\" + '.pdf')\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X4z9YdHaP23"
      },
      "source": [
        "### PERFORMANCE OVER CONSTRUCTION PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9gp-qPtfWAE"
      },
      "outputs": [],
      "source": [
        "for algorithm_name in algorithm_names:\n",
        "  printmd(\"# **\" + algorithm_name + \"**\")\n",
        "  df_algorithm = df_results.loc[df_results['AlgorithmType'] == algorithm_name]\n",
        "  hyperparam_sets = df_algorithm['Hyperparameters'].unique().tolist()\n",
        "\n",
        "  for dataset_name in dataset_names:\n",
        "    printmd(\"## **\" + dataset_name + \"**\")\n",
        "    df_dataset = df_algorithm.loc[df_algorithm['DatasetType'] == dataset_name]\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 5))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "    for hyperparam_set in hyperparam_sets:\n",
        "      df = df_dataset.loc[df_dataset['Hyperparameters'] == hyperparam_set]\n",
        "\n",
        "      if df.empty:\n",
        "        continue\n",
        "\n",
        "      dataset_name_actual = dataset_name\n",
        "      if dataset_name == \"Curves\":\n",
        "        dataset_name_actual = \"Moons\"\n",
        "      if dataset_name == \"Compound\":\n",
        "        dataset_name_actual = \"Classification\"\n",
        "\n",
        "      df_prune = df.loc[df['PruningActive'] == False]\n",
        "      if not df_prune.empty:\n",
        "        x = [1] + get_mean_list(df_prune[\"ConstructionTotalParameters\"])\n",
        "        y = [0.0] + get_mean_list(df_prune[\"ConstructionAccuracy\"])\n",
        "        ax.plot(x, y)\n",
        "        #ax.set_xscale('log')\n",
        "        ax.set_title(dataset_name_actual + \" - Network Construction\", fontsize = 18)\n",
        "        ax.set_xlim([0, 200])\n",
        "        ax.set_xlabel(\"Network Parameters\")\n",
        "        ax.set_ylim([0, 1])\n",
        "        ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "    plt.legend(loc='lower right')\n",
        "    #plt.show()\n",
        "    plt.savefig(\"Param_\" + dataset_name_actual + \"_NoPrune\" + '.pdf')\n",
        "\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 5))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "    for hyperparam_set in hyperparam_sets:\n",
        "      df = df_dataset.loc[df_dataset['Hyperparameters'] == hyperparam_set]\n",
        "\n",
        "      if df.empty:\n",
        "        continue\n",
        "\n",
        "      dataset_name_actual = dataset_name\n",
        "      if dataset_name == \"Curves\":\n",
        "        dataset_name_actual = \"Moons\"\n",
        "      if dataset_name == \"Compound\":\n",
        "        dataset_name_actual = \"Classification\"\n",
        "\n",
        "      df_prune = df.loc[df['PruningActive'] == True]\n",
        "      if not df_prune.empty:\n",
        "        x = [1] + get_mean_list(df_prune[\"ConstructionTotalParameters\"])\n",
        "        y = [0.0] + get_mean_list(df_prune[\"ConstructionAccuracy\"])\n",
        "        ax.plot(x, y, label=hyperparam_set)\n",
        "        #ax.set_xscale('log')\n",
        "        ax.set_title(dataset_name_actual + \" - Network Construction (Pruning)\", fontsize = 18)\n",
        "        ax.set_xlim([0, 200])\n",
        "        ax.set_xlabel(\"Network Parameters\")\n",
        "        ax.set_ylim([0, 1])\n",
        "        ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "    plt.legend(loc='lower right')\n",
        "    #plt.show()\n",
        "    plt.savefig(\"Param_\" + dataset_name_actual + \"_Prune\" + '.pdf')\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "  print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMPARISONS"
      ],
      "metadata": {
        "id": "30zsaTrWX4Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "algorithm_names = df_comparisons['AlgorithmType'].unique().tolist()\n",
        "dataset_names = df_comparisons['DatasetType'].unique().tolist()\n",
        "\n",
        "for dataset_name in dataset_names:\n",
        "  printmd(\"## **\" + dataset_name + \"**\")\n",
        "  df_dataset = df_comparisons.loc[df_comparisons['DatasetType'] == dataset_name]\n",
        "\n",
        "  fig = plt.figure(figsize=(8, 5))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  dataset_name_actual = dataset_name\n",
        "  if dataset_name == \"Curves\":\n",
        "    dataset_name_actual = \"Moons\"\n",
        "  if dataset_name == \"Compound\":\n",
        "    dataset_name_actual = \"Classification\"\n",
        "\n",
        "  for algorithm_name in algorithm_names:\n",
        "    df_algorithm = df_dataset.loc[df_dataset['AlgorithmType'] == algorithm_name]\n",
        "    df_prune = df_algorithm.loc[df_algorithm['PruningActive'] == False]\n",
        "\n",
        "    algorithm_name_actual = algorithm_name\n",
        "    if algorithm_name == \"CCG_DLNN\":\n",
        "      algorithm_name_actual = \"CCG-DLNN\"\n",
        "\n",
        "    x = [1] + get_mean_list2(df_prune[\"ConstructionTotalParameters\"])\n",
        "    y = [0.0] + get_mean_list2(df_prune[\"ConstructionAccuracy\"])\n",
        "    ax.plot(x, y, label=algorithm_name_actual)\n",
        "    #ax.set_xscale('log')\n",
        "    ax.set_title(dataset_name_actual + \" - Network Construction\", fontsize = 18)\n",
        "    #ax.set_xlim([0, len(y)])\n",
        "    ax.set_xlabel(\"Network Parameters\")\n",
        "    ax.set_ylim([0, 1])\n",
        "    ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "  plt.legend(loc='lower right')\n",
        "  #plt.show()\n",
        "  plt.savefig(\"Param_\" + dataset_name + \"_NoPrune\" + '.pdf')\n",
        "\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "zm5l7uFTX66G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algorithm_names = df_comparisons['AlgorithmType'].unique().tolist()\n",
        "dataset_names = df_comparisons['DatasetType'].unique().tolist()\n",
        "\n",
        "for dataset_name in dataset_names:\n",
        "  printmd(\"## **\" + dataset_name + \"**\")\n",
        "  df_dataset = df_comparisons.loc[df_comparisons['DatasetType'] == dataset_name]\n",
        "\n",
        "  fig = plt.figure(figsize=(8, 5))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  dataset_name_actual = dataset_name\n",
        "  if dataset_name == \"Curves\":\n",
        "    dataset_name_actual = \"Moons\"\n",
        "  if dataset_name == \"Compound\":\n",
        "    dataset_name_actual = \"Classification\"\n",
        "\n",
        "  for algorithm_name in algorithm_names:\n",
        "    df_algorithm = df_dataset.loc[df_dataset['AlgorithmType'] == algorithm_name]\n",
        "    df_prune = df_algorithm.loc[df_algorithm['PruningActive'] == False]\n",
        "\n",
        "    x = [0] + get_mean_list2(df_prune[\"ConstructionStep\"])\n",
        "    y = [0.0] + get_mean_list2(df_prune[\"ConstructionAccuracy\"])\n",
        "    #ax.plot(x, y, label=re.sub('[^0-9,]', '', hyperparam_set))\n",
        "    ax.plot(x, y, label=algorithm_name)\n",
        "    #ax.set_xscale('log')\n",
        "    ax.set_title(dataset_name_actual + \" - Network Construction\", fontsize = 18)\n",
        "    #ax.set_xlim([0, len(y)])\n",
        "    ax.set_xlabel(\"Construction Step\")\n",
        "    ax.set_ylim([0, 1])\n",
        "    ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "  plt.legend(loc='lower right')\n",
        "  #plt.show()\n",
        "  plt.savefig(\"Param_\" + dataset_name + \"_NoPrune\" + '.pdf')\n",
        "\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "5E5Y65CHbQip"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}